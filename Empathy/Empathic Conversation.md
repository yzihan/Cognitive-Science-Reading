## Empathic Conversation

#### Human-AI Collaboration Enables More Empathic Conversations in Text-based Peer-to-Peer Mental Health Support

Ashish Sharma, Inna Lin, Adam Miner, David Atkins, *Tim Althoff*

Nature Machine Intelligence 2023

**Abstract **

Advances in artificial intelligence (AI) are enabling systems that augment and collaborate with humans to perform simple, mechanistic tasks like scheduling meetings and grammar-checking text. However, such Human-AI collaboration poses challenges for more complex, creative tasks, such as carrying out empathic conversations, due to difficulties of AI systems in understanding complex human emotions and the open-ended nature of these tasks. Here, we focus on peer-to-peer mental health support, a setting in which empathy is critical for success, and examine how AI can collaborate with humans to facilitate peer empathy during textual, online supportive conversations. We develop HAILEY, an AI-in-the-loop agent that provides just-in-time feedback to help participants who provide support (peer supporters) respond more empathically to those seeking help (support seekers). We evaluate HAILEY in a non-clinical randomized controlled trial with real-world peer supporters on TalkLife (N=300), a large online peer-topeer support platform. We show that our Human-AI collaboration approach leads to a 19.60% increase in conversational empathy between peers overall. Furthermore, we find a larger 38.88% increase in empathy within the subsample of peer supporters who self-identify as experiencing difficulty providing support. We systematically analyze the Human-AI collaboration patterns and find that peer supporters are able to use the AI feedback both directly and indirectly without becoming overly reliant on AI while reporting improved self-efficacy post-feedback. Our findings demonstrate the potential of feedback-driven, AI-in-the-loop writing systems to empower humans in open-ended, social, creative tasks such as empathic conversations.



#### A Computational Approach to Understanding Empathy Expressed in Text-Based Mental Health Support

[Ashish Sharma](https://aclanthology.org/people/a/ashish-sharma/), [Adam Miner](https://aclanthology.org/people/a/adam-miner/), [David Atkins](https://aclanthology.org/people/d/david-atkins/), [Tim Althoff](https://aclanthology.org/people/t/tim-althoff/)

https://aclanthology.org/2020.emnlp-main.425/

**Abstract**

> Empathy is critical to successful mental health support. Empathy measurement has predominantly occurred in synchronous, face-toface settings, and may not translate to asynchronous, text-based contexts. Because millions of people use text-based platforms for mental health support, understanding empathy in these contexts is crucial. In this work, we present a computational approach to understanding how empathy is expressed in online mental health platforms. We develop a novel unifying theoretically-grounded framework for characterizing the communication of empathy in text-based conversations. We collect and share a corpus of 10k (post, response) pairs annotated using this empathy framework with supporting evidence for annotations (rationales). We develop a multi-task RoBERTa-based bi-encoder model for identifying empathy in conversations and extracting rationales underlying its predictions. Experiments demonstrate that our approach can effectively identify empathic conversations. We further apply this model to analyze 235k mental health interactions and show that users do not self-learn empathy over time, revealing opportunities for empathy training and feedback.

##### How to measure empathy

> Empathy is a complex multi-dimensional construct with two broad aspects related to emotion and cognition (Davis et al., 1980). The “emotion” aspect relates to the emotional stimulation in reaction to the experiences and feelings expressed by a user. The “cognition” aspect is a more deliberate process of understanding and interpreting the experiences and feelings of the user and communicating that understanding to them (Elliott et al., 2018).

> Here, we study expressed empathy in text-based mental health support– empathy expressed or communicated by peer supporters in their textual interactions with seekers (cf. Barrett-Lennard (1981)).3 Table 1 lists existing empathy scales in psychology and psychotherapy research. Truax and Carkhuff (1967) focus only on communicating cognitive understanding of others while Davis et al. (1980); Watson et al. (2002) also make use of expressing stimulated emotions.

> These scales, however, have been designed for in-person interactions and face-to-face therapy, often leveraging audio-visual signals like expressive voice. In contrast, in text-based support, empathy must be expressed using textual response alone. Also, they are designed to operate on long, synchronous conversations and are unsuited for the shorter, asynchronous conversations of our context.

> In this work, we adapt these scales to text-based, asynchronous support. We develop a new comprehensive framework for text-based, asynchronous conversations (Table 1; §3), use it to create a new dataset of empathic conversations (§4), a computational approach for identifying empathy (§5; §6), & gaining insights into mental health platforms (§7).

### Davis, M. H. A. et al. A multidimensional approach to individual differences in empathy. J. Pers. Soc. Psychol. (1980).

Elliott, R., Bohart, A. C., Watson, J. C. & Murphy, D. Therapist empathy and client outcome: An updated meta-analysis. Psychotherapy 55, 399–410 (2018)

**Abstract**

The development of a multidimensional individual difference measure of empathy is
described. The final version of the instrument consists of four seven-item subscales, each of
which taps a separate aspect of the global concept "empathy." One scale, the perspective-taking
scale, contains items which assess spontaneous attempts to adopt the perspectives of other people
and see things from their point of view. Items on the fantasy scale measure the tendency to
identify with characters in movies, novels, plays and other fictional situations. The other two
subscales explicitly tap respondents' chronic emotional reactions to the negative experiences of
others. The empathic concern scale inquires about respondents' feelings of warmth, compassion,
and concern for others, while the personal distress scale measures the personal feelings of anxiety
and discomfort that result from observing another's negative experience. The factor structure
underlying these scales is the same for both sexes, and emerged in two independent samples.
Test-retest and internal reliabilities of all four scales were substantial. The pattern of sex
differences and the intercorrelations of these four scales are discussed in terms of recent
theoretical treatments of the development of empathy (Hoffman, 1976). It is concluded that the
new measure has considerable potential for investigations of the multidimensional nature of
empathy. 


### The Effect of Moderation on Online Mental Health Conversations

doi: https://doi.org/10.48550/arXiv.2005.09225


**Abstract**

>Many people struggling with mental health issues are unable to access adequate care due to high costs and a shortage of mental health professionals, leading to a global mental health crisis. Online mental health communities can help mitigate this crisis by offering a scalable, easily accessible alternative to in-person sessions with therapists or support groups. However, people seeking emotional or psychological support online may be especially vulnerable to the kinds of antisocial behavior that sometimes occur in online discussions. Moderation can improve online discourse quality, but we lack an understanding of its effects on online mental health conversations. In this work, we leveraged a natural experiment, occurring across 200,000 messages from 7,000 online mental health conversations, to evaluate the effects of moderation on online mental health discussions. We found that participation in group mental health discussions led to improvements in psychological perspective, and that these improvements were larger in moderated conversations. The presence of a moderator increased user engagement, encouraged users to discuss negative emotions more candidly, and dramatically reduced bad behavior among chat participants. Moderation also encouraged stronger linguistic coordination, which is indicative of trust building. In addition, moderators who remained active in conversations were especially successful in keeping conversations on topic. Our findings suggest that moderation can serve as a valuable tool to improve the efficacy and safety of online mental health conversations. Based on these findings, we discuss implications and trade-offs involved in designing effective online spaces for mental health support.
> Moderators were undergraduate or graduate students pursuing degrees in psychology, who had completed training by the platform on peer support facilitation. 