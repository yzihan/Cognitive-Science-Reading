### EmotionCues: Emotion-Oriented Visual Summarization of Classroom Videos

**Abstract**

>Analyzing studentsâ€™ emotions from classroom videos can help both teachers and parents quickly know the engagement of students in class. The availability of high-definition cameras creates opportunities to record class scenes. However, watching videos is time-consuming, and it is challenging to gain a quick overview of the emotion distribution and find abnormal emotions. In this article, we propose EmotionCues , a visual analytics system to easily analyze classroom videos from the perspective of emotion summary and detailed analysis, which integrates emotion recognition algorithms with visualizations. It consists of three coordinated views: a summary view depicting the overall emotions and their dynamic evolution, a character view presenting the detailed emotion status of an individual, and a video view enhancing the video analysis with further details. Considering the possible inaccuracy of emotion recognition, we also explore several factors affecting the emotion analysis, such as face size and occlusion. They provide hints for inferring the possible inaccuracy and the corresponding reasons. Two use cases and interviews with end users and domain experts are conducted to show that the proposed system could be useful and effective for analyzing emotions in the classroom videos.

### Bifurcating Cognitive Attention from Visual Concentration: Utilizing Cooperative Audiovisual Sensing for Demarcating Inattentive Online Meeting Participants

**Abstract**

> The profuse popularity of video conferencing has led to a simultaneous rise in the opportunity for the participants to multitask. Productive multitasking, such as taking notes, browsing for relevant information, etc., can help promote the cognitive attentiveness of participants. However, existing approaches of tagging inattentive participants solely based on their visual concentration on the meeting app fail to work in such instances. This paper proposes EmotiConf -- a novel real-time framework to monitor participants' attentiveness and a non-real-time framework for visual multitask detection without explicitly relying on their visual concentration. EmotiConf utilizes an unconventional observation where the emotional states of attentive participants, captured through their facial expressions, correlate and also correspond to the vocal expression of the speaker and the intent of the speech. Accordingly, EmotiConf develops a software wrapper to tag the inattentive participants while also characterizing visual multitasking instances performed by them. A thorough evaluation of EmotiConf confirms its usability with a high score of >80.\

**Insights**

> 1. Multi-cues for emotion tag in dream: text, color, music, self-evaluaion