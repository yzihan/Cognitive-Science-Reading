Miner AS, Milstein A, Hancock JT. Talking to machines about personal mental health problems. JAMA (2017) 318(13):1217–8. doi: 10.1001/jama.2017.14151

Fitzpatrick KK, Darcy A, Vierhile M. Delivering cognitive behavior therapy to young adults with symptoms of depression and anxiety using a fully automated conversational agent (Woebot): a randomized controlled trial. JMIR Ment Health (2017) 4(2):e19. doi: 10.2196/mental.7785

Oh KJ, Lee D, Ko B, Choi HJ. A chatbot for psychiatric counseling in mental healthcare service based on emotional dialogue analysis and sentence generation. Mobile Data Management (MDM), 2017 18th IEEE International Conference; 29.IEEE. (2017) pp. 371–375. doi: 10.1109/MDM.2017.64

Luxton DD. Artificial intelligence in behavioral and mental health care. Elsevier/Academic Press (2016). doi: 10.1016/B978-0-12-420248-1.00001-5

Rehm IC, Foenander E, Wallace K, Abbott JA, Kyrios M, Thomas N. What role can avatars play in e-mental health interventions? Front Psychiatry (2016) 7:186. doi: 10.3389/fpsyt.2016.00186

Althoff T, Clark K, Leskovec J. Large-scale analysis of counseling conversations: an application of natural language processing to mental health. Trans Assoc Comput Lingu (2016) 4:463. doi: 10.1162/tacl_a_00111

Kazdin AE, Rabbitt SM. Novel models for delivering mental health services and reducing the burdens of mental illness. Clin Psychol Sci (2013) 1(2):170–91. doi: 10.1177/2167702612463566

Miner AS, Milstein A, Schueller S, Hegde R, Mangurian C, Linos E. Smartphone-based conversational agents and responses to questions about mental health, interpersonal violence, and physical health. JAMA Int Med (2016) 176(5):619–25. doi: 10.1001/jamainternmed.2016.0400

### Developing an Artificially Intelligent Tool for Grief Recovery

doi: 

**Abstract**
> Artificially intelligent technologies have replaced humans in physically heavy and monotoneduties, and have more recently slid into our daily lives, from robot vacuum cleaners, to personal assistants like Apples Siri, to targeted advertisements in social media. This master thesis researches how AI can be incorporated in personal aspects of life, such as in a grieving process, and aims to develop a relevant tool, employing a user centered design (UCD) methodology. User-centered design puts the user in the center of the research, design and decision process. In this report, ‘user’ refers to griever. However, other stakeholders are also considered in the designprocess. A theoretical pre-study was carried out through literature, research, and expert opinions on the topics relevant to the thesis. The focus areas were AI, Human-Computer Interaction, User-Centered design and grief and the grieving process. A user study regarding grief and the grieving process was conducted to get further insights and confirm the theory. Semi-structured interviews and an online survey were employed, which were analyzed and translated into the insights that served as the foundation for ideation. Ideation resulted in six concepts which were analyzed using SWOT matrices and user tests with trigger materials. The analyses were used to eliminate five concepts. The user studies and research showed that talking about personal grief is the most successful way to process the grief, and best results were gained if the communication was with someone who had gone through something similar. This insight served as the root for the idea to create Tuki. The final concept is a mobile application Tuki (meaning ‘support’ in Finnish) which uses Natural Language Processing (NLP) to analyze the users’ input data regarding their situation, and then matches them to another user with similar experiences.The concept was tested and developed with users in workshops using paper wireframes to get as good a user experience as possible. From these workshops a prototype, service blueprints and astory board were created to envision and describe the user journey with Tuki. Tuki fulfills the goals of the thesis by using AI technology, specifically natural language processing, to ease an identified pain point in the grieving process: the limited possibilities to get in contact with others who had gone through a similar grieving process.


### The "Conversation" about Loss : Understanding How Chatbot Technology was Used in Supporting People in Grief. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems . (In press)

**Abstract**
> While conversational agents have traditionally been used for simple tasks such as scheduling meetings and customer service support,
recent advancements have led researchers to examine their use in complex social situations, such as to provide emotional support and
companionship. For mourners who could be vulnerable to the sense of loneliness and disruption of self-identity, such technology
offers a unique way to help them cope with grief. In this study, we explore the potential benefits and risks of such a practice, through
semi-structured interviews with 10 mourners who actively used chatbots at different phases of their loss. Our findings indicated seven
approaches in which chatbots were used to help people cope with grief, by taking the role of listener, acting as a simulation of the
deceased, romantic partner, friend and emotion coach. We then highlight how interacting with the chatbots impacted mourners’ grief
experience and conclude the paper with further research opportunities.

**Insights**
1. Chatbot-Generated Emotional Support (CGES)
2. grief therapy

### Can a Recommender System Support Treatment Personalisation in Digital Mental Health Therapy?

doi: https://doi.org/10.1145/3491101.3519840

**Abstract**
Recommender systems have the potential to improve the user experience of mental health apps. Personalised recommendations can help users to identify therapy tasks that they find most enjoyable or helpful, thus boosting their engagement with the service and optimising the extent to which it helps them to feel better. Using a dataset containing 23,476 ratings collected from 973 players of a mental health therapy game, this work demonstrates how collaborative filtering algorithms can predict how much a user will benefit from a new therapy task with greater accuracy than a simpler baseline algorithm that predicts the average rating for a task, adjusted for the biases of the specific user and specific task. Collaborative filtering algorithms (matrix factorisation and k-nearest neighbour) outperform this baseline with a 6.5-8.3% improvement in mean absolute error (MAE) and context-aware collaborative filtering algorithms (factorisation machines) outperform with a 7.8-8.8\% improvement in MAE. These results suggest that recommender systems could be a useful tool for tailoring recommendations of new therapy tasks to a user based on a combination of their past preferences, the ratings of similar users, and their current context. This scalable approach to personalisation -- which does not require a human therapist to always be in-the-loop -- could play an important role in improving engagement and outcomes in digital mental health therapies.

